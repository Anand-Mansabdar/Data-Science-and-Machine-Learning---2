{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2edffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"Good morning everyone,\n",
    "Today, I don’t want to talk to you about success.\n",
    "I don’t want to talk about failure either.\n",
    "I want to talk to you about the space between the two — the part no one posts on LinkedIn, no one puts on Instagram, and no one applauds.\n",
    "That space is called the journey.\n",
    "You see, we live in a world that celebrates outcomes.\n",
    "We clap for degrees, titles, salaries, rankings, followers, and results.\n",
    "But we rarely talk about the nights of doubt, the confusion, the fear of being left behind, and the quiet resilience it takes to keep going when nobody is watching.\n",
    "Every single person sitting here today is on a different timeline.\n",
    "And yet, we constantly compare our Chapter 3 with someone else’s Chapter 20.\n",
    "Let me tell you something important:\n",
    "Life is not a race. It is a process.\n",
    "Some people discover their purpose early.\n",
    "Some discover it late.\n",
    "Some change it multiple times.\n",
    "None of that makes you behind.\n",
    "What does put you behind is quitting on yourself because your progress doesn’t look like someone else’s highlight reel.\n",
    "You will have moments where you question your abilities.\n",
    "Moments where you wonder if you chose the right path.\n",
    "Moments where you feel like everyone else has figured it out except you.\n",
    "Let me be honest with you — most people are figuring it out as they go.\n",
    "Confidence is not clarity.\n",
    "Often, it’s just courage wearing a calm face.\n",
    "The truth is, growth is uncomfortable.\n",
    "Transformation is messy.\n",
    "And progress is often invisible while it’s happening.\n",
    "When you plant a seed, you don’t dig it up every day to check if it’s growing.\n",
    "You water it.\n",
    "You protect it.\n",
    "You trust the process.\n",
    "It tells you what didn’t work.\n",
    "It sharpens your judgment.\n",
    "It humbles your ego and strengthens your character.\n",
    "The only real failure is refusing to learn.\n",
    "So walk out of this room with patience for yourself.\n",
    "With belief in your ability to grow.\n",
    "And with the courage to continue, even when the path feels unclear.\n",
    "Your story is still being written.\n",
    "And the next chapter is waiting for you to show up.\n",
    "Thank you.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b2b4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e6d8fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de5979d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aber',\n",
       " 'alle',\n",
       " 'allem',\n",
       " 'allen',\n",
       " 'aller',\n",
       " 'alles',\n",
       " 'als',\n",
       " 'also',\n",
       " 'am',\n",
       " 'an',\n",
       " 'ander',\n",
       " 'andere',\n",
       " 'anderem',\n",
       " 'anderen',\n",
       " 'anderer',\n",
       " 'anderes',\n",
       " 'anderm',\n",
       " 'andern',\n",
       " 'anderr',\n",
       " 'anders',\n",
       " 'auch',\n",
       " 'auf',\n",
       " 'aus',\n",
       " 'bei',\n",
       " 'bin',\n",
       " 'bis',\n",
       " 'bist',\n",
       " 'da',\n",
       " 'damit',\n",
       " 'dann',\n",
       " 'der',\n",
       " 'den',\n",
       " 'des',\n",
       " 'dem',\n",
       " 'die',\n",
       " 'das',\n",
       " 'dass',\n",
       " 'daß',\n",
       " 'derselbe',\n",
       " 'derselben',\n",
       " 'denselben',\n",
       " 'desselben',\n",
       " 'demselben',\n",
       " 'dieselbe',\n",
       " 'dieselben',\n",
       " 'dasselbe',\n",
       " 'dazu',\n",
       " 'dein',\n",
       " 'deine',\n",
       " 'deinem',\n",
       " 'deinen',\n",
       " 'deiner',\n",
       " 'deines',\n",
       " 'denn',\n",
       " 'derer',\n",
       " 'dessen',\n",
       " 'dich',\n",
       " 'dir',\n",
       " 'du',\n",
       " 'dies',\n",
       " 'diese',\n",
       " 'diesem',\n",
       " 'diesen',\n",
       " 'dieser',\n",
       " 'dieses',\n",
       " 'doch',\n",
       " 'dort',\n",
       " 'durch',\n",
       " 'ein',\n",
       " 'eine',\n",
       " 'einem',\n",
       " 'einen',\n",
       " 'einer',\n",
       " 'eines',\n",
       " 'einig',\n",
       " 'einige',\n",
       " 'einigem',\n",
       " 'einigen',\n",
       " 'einiger',\n",
       " 'einiges',\n",
       " 'einmal',\n",
       " 'er',\n",
       " 'ihn',\n",
       " 'ihm',\n",
       " 'es',\n",
       " 'etwas',\n",
       " 'euer',\n",
       " 'eure',\n",
       " 'eurem',\n",
       " 'euren',\n",
       " 'eurer',\n",
       " 'eures',\n",
       " 'für',\n",
       " 'gegen',\n",
       " 'gewesen',\n",
       " 'hab',\n",
       " 'habe',\n",
       " 'haben',\n",
       " 'hat',\n",
       " 'hatte',\n",
       " 'hatten',\n",
       " 'hier',\n",
       " 'hin',\n",
       " 'hinter',\n",
       " 'ich',\n",
       " 'mich',\n",
       " 'mir',\n",
       " 'ihr',\n",
       " 'ihre',\n",
       " 'ihrem',\n",
       " 'ihren',\n",
       " 'ihrer',\n",
       " 'ihres',\n",
       " 'euch',\n",
       " 'im',\n",
       " 'in',\n",
       " 'indem',\n",
       " 'ins',\n",
       " 'ist',\n",
       " 'jede',\n",
       " 'jedem',\n",
       " 'jeden',\n",
       " 'jeder',\n",
       " 'jedes',\n",
       " 'jene',\n",
       " 'jenem',\n",
       " 'jenen',\n",
       " 'jener',\n",
       " 'jenes',\n",
       " 'jetzt',\n",
       " 'kann',\n",
       " 'kein',\n",
       " 'keine',\n",
       " 'keinem',\n",
       " 'keinen',\n",
       " 'keiner',\n",
       " 'keines',\n",
       " 'können',\n",
       " 'könnte',\n",
       " 'machen',\n",
       " 'man',\n",
       " 'manche',\n",
       " 'manchem',\n",
       " 'manchen',\n",
       " 'mancher',\n",
       " 'manches',\n",
       " 'mein',\n",
       " 'meine',\n",
       " 'meinem',\n",
       " 'meinen',\n",
       " 'meiner',\n",
       " 'meines',\n",
       " 'mit',\n",
       " 'muss',\n",
       " 'musste',\n",
       " 'nach',\n",
       " 'nicht',\n",
       " 'nichts',\n",
       " 'noch',\n",
       " 'nun',\n",
       " 'nur',\n",
       " 'ob',\n",
       " 'oder',\n",
       " 'ohne',\n",
       " 'sehr',\n",
       " 'sein',\n",
       " 'seine',\n",
       " 'seinem',\n",
       " 'seinen',\n",
       " 'seiner',\n",
       " 'seines',\n",
       " 'selbst',\n",
       " 'sich',\n",
       " 'sie',\n",
       " 'ihnen',\n",
       " 'sind',\n",
       " 'so',\n",
       " 'solche',\n",
       " 'solchem',\n",
       " 'solchen',\n",
       " 'solcher',\n",
       " 'solches',\n",
       " 'soll',\n",
       " 'sollte',\n",
       " 'sondern',\n",
       " 'sonst',\n",
       " 'über',\n",
       " 'um',\n",
       " 'und',\n",
       " 'uns',\n",
       " 'unsere',\n",
       " 'unserem',\n",
       " 'unseren',\n",
       " 'unser',\n",
       " 'unseres',\n",
       " 'unter',\n",
       " 'viel',\n",
       " 'vom',\n",
       " 'von',\n",
       " 'vor',\n",
       " 'während',\n",
       " 'war',\n",
       " 'waren',\n",
       " 'warst',\n",
       " 'was',\n",
       " 'weg',\n",
       " 'weil',\n",
       " 'weiter',\n",
       " 'welche',\n",
       " 'welchem',\n",
       " 'welchen',\n",
       " 'welcher',\n",
       " 'welches',\n",
       " 'wenn',\n",
       " 'werde',\n",
       " 'werden',\n",
       " 'wie',\n",
       " 'wieder',\n",
       " 'will',\n",
       " 'wir',\n",
       " 'wird',\n",
       " 'wirst',\n",
       " 'wo',\n",
       " 'wollen',\n",
       " 'wollte',\n",
       " 'würde',\n",
       " 'würden',\n",
       " 'zu',\n",
       " 'zum',\n",
       " 'zur',\n",
       " 'zwar',\n",
       " 'zwischen']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"german\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2230c40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['au',\n",
       " 'aux',\n",
       " 'avec',\n",
       " 'ce',\n",
       " 'ces',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'des',\n",
       " 'du',\n",
       " 'elle',\n",
       " 'en',\n",
       " 'et',\n",
       " 'eux',\n",
       " 'il',\n",
       " 'ils',\n",
       " 'je',\n",
       " 'la',\n",
       " 'le',\n",
       " 'les',\n",
       " 'leur',\n",
       " 'lui',\n",
       " 'ma',\n",
       " 'mais',\n",
       " 'me',\n",
       " 'même',\n",
       " 'mes',\n",
       " 'moi',\n",
       " 'mon',\n",
       " 'ne',\n",
       " 'nos',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'on',\n",
       " 'ou',\n",
       " 'par',\n",
       " 'pas',\n",
       " 'pour',\n",
       " 'qu',\n",
       " 'que',\n",
       " 'qui',\n",
       " 'sa',\n",
       " 'se',\n",
       " 'ses',\n",
       " 'son',\n",
       " 'sur',\n",
       " 'ta',\n",
       " 'te',\n",
       " 'tes',\n",
       " 'toi',\n",
       " 'ton',\n",
       " 'tu',\n",
       " 'un',\n",
       " 'une',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'c',\n",
       " 'd',\n",
       " 'j',\n",
       " 'l',\n",
       " 'à',\n",
       " 'm',\n",
       " 'n',\n",
       " 's',\n",
       " 't',\n",
       " 'y',\n",
       " 'été',\n",
       " 'étée',\n",
       " 'étées',\n",
       " 'étés',\n",
       " 'étant',\n",
       " 'étante',\n",
       " 'étants',\n",
       " 'étantes',\n",
       " 'suis',\n",
       " 'es',\n",
       " 'est',\n",
       " 'sommes',\n",
       " 'êtes',\n",
       " 'sont',\n",
       " 'serai',\n",
       " 'seras',\n",
       " 'sera',\n",
       " 'serons',\n",
       " 'serez',\n",
       " 'seront',\n",
       " 'serais',\n",
       " 'serait',\n",
       " 'serions',\n",
       " 'seriez',\n",
       " 'seraient',\n",
       " 'étais',\n",
       " 'était',\n",
       " 'étions',\n",
       " 'étiez',\n",
       " 'étaient',\n",
       " 'fus',\n",
       " 'fut',\n",
       " 'fûmes',\n",
       " 'fûtes',\n",
       " 'furent',\n",
       " 'sois',\n",
       " 'soit',\n",
       " 'soyons',\n",
       " 'soyez',\n",
       " 'soient',\n",
       " 'fusse',\n",
       " 'fusses',\n",
       " 'fût',\n",
       " 'fussions',\n",
       " 'fussiez',\n",
       " 'fussent',\n",
       " 'ayant',\n",
       " 'ayante',\n",
       " 'ayantes',\n",
       " 'ayants',\n",
       " 'eu',\n",
       " 'eue',\n",
       " 'eues',\n",
       " 'eus',\n",
       " 'ai',\n",
       " 'as',\n",
       " 'avons',\n",
       " 'avez',\n",
       " 'ont',\n",
       " 'aurai',\n",
       " 'auras',\n",
       " 'aura',\n",
       " 'aurons',\n",
       " 'aurez',\n",
       " 'auront',\n",
       " 'aurais',\n",
       " 'aurait',\n",
       " 'aurions',\n",
       " 'auriez',\n",
       " 'auraient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avions',\n",
       " 'aviez',\n",
       " 'avaient',\n",
       " 'eut',\n",
       " 'eûmes',\n",
       " 'eûtes',\n",
       " 'eurent',\n",
       " 'aie',\n",
       " 'aies',\n",
       " 'ait',\n",
       " 'ayons',\n",
       " 'ayez',\n",
       " 'aient',\n",
       " 'eusse',\n",
       " 'eusses',\n",
       " 'eût',\n",
       " 'eussions',\n",
       " 'eussiez',\n",
       " 'eussent']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"french\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0832fef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "sentences = nltk.sent_tokenize(corpus)\n",
    "type(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9cc369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply stopwords and filter the words and then apply stemming\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "  words = nltk.word_tokenize(sentences[i])\n",
    "  words = [stemmer.stem(word) for word in words if word not in set(stopwords.words(\"english\"))]\n",
    "  sentences[i] = \"  \".join(words) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6ca9f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good  morn  everyon  ,  today  ,  ’  want  talk  success  .',\n",
       " '’  want  talk  failur  either  .',\n",
       " 'want  talk  space  two  —  part  one  post  linkedin  ,  one  put  instagram  ,  one  applaud  .',\n",
       " 'space  call  journey  .',\n",
       " 'see  ,  live  world  celebr  outcom  .',\n",
       " 'clap  degr  ,  titl  ,  salari  ,  rank  ,  follow  ,  result  .',\n",
       " 'rare  talk  night  doubt  ,  confu  ,  fear  left  behind  ,  quiet  resili  take  keep  go  nobodi  watch  .',\n",
       " 'everi  singl  person  sit  today  differ  timelin  .',\n",
       " 'yet  ,  constantli  compar  chapter  3  someon  el  ’  chapter  20  .',\n",
       " 'let  tell  someth  import  :  life  race  .',\n",
       " 'process  .',\n",
       " 'peopl  discov  purpo  earli  .',\n",
       " 'discov  late  .',\n",
       " 'chang  multipl  time  .',\n",
       " 'none  make  behind  .',\n",
       " 'put  behind  quit  progress  ’  look  like  someon  el  ’  highlight  reel  .',\n",
       " 'moment  question  abil  .',\n",
       " 'moment  wonder  chose  right  path  .',\n",
       " 'moment  feel  like  everyon  el  figur  except  .',\n",
       " 'let  honest  —  peopl  figur  go  .',\n",
       " 'confid  clariti  .',\n",
       " 'often  ,  ’  courag  wear  calm  face  .',\n",
       " 'truth  ,  growth  uncomfort  .',\n",
       " 'transform  messi  .',\n",
       " 'progress  often  invi  ’  happen  .',\n",
       " 'plant  seed  ,  ’  dig  everi  day  check  ’  grow  .',\n",
       " 'water  .',\n",
       " 'protect  .',\n",
       " 'trust  process  .',\n",
       " 'tell  ’  work  .',\n",
       " 'sharpen  judgment  .',\n",
       " 'humbl  ego  strengthen  charact  .',\n",
       " 'real  failur  refu  learn  .',\n",
       " 'walk  room  patienc  .',\n",
       " 'belief  abil  grow  .',\n",
       " 'courag  continu  ,  even  path  feel  unclear  .',\n",
       " 'stori  still  written  .',\n",
       " 'next  chapter  wait  show  .',\n",
       " 'thank  .']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c0ab37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowStem = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "007d9b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "  words = nltk.word_tokenize(sentences[i])\n",
    "  words = [snowStem.stem(word) for word in words if word not in set(stopwords.words(\"english\"))]\n",
    "  sentences[i] = \"  \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb606385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good  morn  everyon  ,  today  ,  i  ’  want  talk  success  .',\n",
       " 'i  ’  want  talk  failur  either  .',\n",
       " 'i  want  talk  space  two  —  part  one  post  linkedin  ,  one  put  instagram  ,  one  applaud  .',\n",
       " 'that  space  call  journey  .',\n",
       " 'you  see  ,  live  world  celebr  outcom  .',\n",
       " 'we  clap  degre  ,  titl  ,  salari  ,  rank  ,  follow  ,  result  .',\n",
       " 'but  rare  talk  night  doubt  ,  confus  ,  fear  left  behind  ,  quiet  resili  take  keep  go  nobodi  watch  .',\n",
       " 'everi  singl  person  sit  today  differ  timelin  .',\n",
       " 'and  yet  ,  constant  compar  chapter  3  someon  els  ’  chapter  20  .',\n",
       " 'let  tell  someth  import  :  life  race  .',\n",
       " 'it  process  .',\n",
       " 'some  peopl  discov  purpos  earli  .',\n",
       " 'some  discov  late  .',\n",
       " 'some  chang  multipl  time  .',\n",
       " 'none  make  behind  .',\n",
       " 'what  put  behind  quit  progress  ’  look  like  someon  els  ’  highlight  reel  .',\n",
       " 'you  moment  question  abil  .',\n",
       " 'moment  wonder  chose  right  path  .',\n",
       " 'moment  feel  like  everyon  els  figur  except  .',\n",
       " 'let  honest  —  peopl  figur  go  .',\n",
       " 'confid  clariti  .',\n",
       " 'often  ,  ’  courag  wear  calm  face  .',\n",
       " 'the  truth  ,  growth  uncomfort  .',\n",
       " 'transform  messi  .',\n",
       " 'and  progress  often  invis  ’  happen  .',\n",
       " 'when  plant  seed  ,  ’  dig  everi  day  check  ’  grow  .',\n",
       " 'you  water  .',\n",
       " 'you  protect  .',\n",
       " 'you  trust  process  .',\n",
       " 'it  tell  ’  work  .',\n",
       " 'it  sharpen  judgment  .',\n",
       " 'it  humbl  ego  strengthen  charact  .',\n",
       " 'the  real  failur  refus  learn  .',\n",
       " 'so  walk  room  patienc  .',\n",
       " 'with  belief  abil  grow  .',\n",
       " 'and  courag  continu  ,  even  path  feel  unclear  .',\n",
       " 'your  stori  still  written  .',\n",
       " 'and  next  chapter  wait  show  .',\n",
       " 'thank  .']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9374bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53a44e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "  words = nltk.word_tokenize(sentences[i])\n",
    "  words = [wnl.lemmatize(word.lower(), pos=\"v\") for word in words if word not in set(stopwords.words(\"english\"))]\n",
    "  sentences[i] = \"  \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20c16914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good  morning  everyone  ,  today  ,  i  ’  want  talk  success  .',\n",
       " 'i  ’  want  talk  failure  either  .',\n",
       " 'i  want  talk  space  two  —  part  one  post  linkedin  ,  one  put  instagram  ,  one  applaud  .',\n",
       " 'that  space  call  journey  .',\n",
       " 'you  see  ,  live  world  celebrate  outcomes  .',\n",
       " 'we  clap  degrees  ,  title  ,  salaries  ,  rankings  ,  followers  ,  result  .',\n",
       " 'but  rarely  talk  nights  doubt  ,  confusion  ,  fear  leave  behind  ,  quiet  resilience  take  keep  go  nobody  watch  .',\n",
       " 'every  single  person  sit  today  different  timeline  .',\n",
       " 'and  yet  ,  constantly  compare  chapter  3  someone  else  ’  chapter  20  .',\n",
       " 'let  tell  something  important  :  life  race  .',\n",
       " 'it  process  .',\n",
       " 'some  people  discover  purpose  early  .',\n",
       " 'some  discover  late  .',\n",
       " 'some  change  multiple  time  .',\n",
       " 'none  make  behind  .',\n",
       " 'what  put  behind  quit  progress  ’  look  like  someone  else  ’  highlight  reel  .',\n",
       " 'you  moments  question  abilities  .',\n",
       " 'moments  wonder  choose  right  path  .',\n",
       " 'moments  feel  like  everyone  else  figure  except  .',\n",
       " 'let  honest  —  people  figure  go  .',\n",
       " 'confidence  clarity  .',\n",
       " 'often  ,  ’  courage  wear  calm  face  .',\n",
       " 'the  truth  ,  growth  uncomfortable  .',\n",
       " 'transformation  messy  .',\n",
       " 'and  progress  often  invisible  ’  happen  .',\n",
       " 'when  plant  seed  ,  ’  dig  every  day  check  ’  grow  .',\n",
       " 'you  water  .',\n",
       " 'you  protect  .',\n",
       " 'you  trust  process  .',\n",
       " 'it  tell  ’  work  .',\n",
       " 'it  sharpen  judgment  .',\n",
       " 'it  humble  ego  strengthen  character  .',\n",
       " 'the  real  failure  refuse  learn  .',\n",
       " 'so  walk  room  patience  .',\n",
       " 'with  belief  ability  grow  .',\n",
       " 'and  courage  continue  ,  even  path  feel  unclear  .',\n",
       " 'your  story  still  write  .',\n",
       " 'and  next  chapter  wait  show  .',\n",
       " 'thank  .']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
